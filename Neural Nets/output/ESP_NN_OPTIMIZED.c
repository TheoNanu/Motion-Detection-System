#include <stdio.h>
#include <stdlib.h>
#include <math.h>

#define INPUT_SIZE 8
#define OUTPUT_SIZE 1

#define ADD(a, b) (a + b)
#define SUBTRACT(a, b) (a - b)
#define MULTIPLY(a, b) (a * b)
#define DIVIDE(a, b) (a / b)
#define sigmoid(x) 1 / (1 + exp(-x))
#define tanh(x) 2 / (1 + exp(-2 * x)) - 1
#define relu(x) x > 0 ? x : 0
#define selu(x) x > 0 ? 1.05070098 * x : 1.05070098 * 1.67326324 * (exp(x) - 1)
#define softplus(x) log(exp(x) + 1)
#define softsign(x) x / (abs(x) + 1)
#define exponential(x) exp(x)
#define elu(x) x > 0 ? x : 1.67326324 * (exp(x) - 1)

float *softmax(float vector[], int len)
{
	float* result = (float*) malloc(len * sizeof(float));

	if(!result)
		return NULL;

	for(int i = 0; i < len; i++)
	{
		float sum = 0;
		for(int j = 0; j < len; j++)
		{
			sum += exp(vector[j]);
		}
		result[i] = exp(vector[i]) / sum;
	}
	return result;
}

static const float bias_0[13] = {0.009300195, -0.085679255, 0.16065636, 0.06013766, 0.058225647, 0.17001246, 0.013843992, -0.007822711, -0.07926345, 0.042329844, 0.0097117005, 0.034515187, 0.04213404};

static const float weights_0[13][8] = {
		{0.019054111, -0.23653652, 0.07618515, 0.35337904, 0.8157437, -0.287333, 0.13479903, 0.25655833},
		{-0.28342143, -0.20387104, -0.45976368, -0.2292048, 0.49921903, -0.44139913, 0.3585302, -0.1739952},
		{-0.07309814, 0.35199648, 0.59423864, 0.5318009, -0.0071158465, 0.32960844, -0.3618689, -0.40722635},
		{-0.13486059, -0.7506604, -0.030221581, 0.6354615, 0.6154188, 0.5797246, -0.19790874, -0.2898798},
		{-0.59447134, -0.18941209, 0.52024543, -0.29965466, 0.23221213, 0.2718794, 0.48181233, 0.411755},
		{0.3328625, 0.14858802, -0.062075302, 0.544968, -0.18471113, -0.02028043, -0.26701486, 0.5791974},
		{0.09259004, -0.6087999, 0.30747992, 0.3113858, 0.5641782, -0.08937894, -0.21122766, -0.3922162},
		{0.45585868, 0.41718042, 0.03999069, 0.006150029, -0.32927835, -0.08812604, -0.42872852, -0.4681049},
		{-0.47866583, -0.17282191, -0.1168046, -0.32020995, -0.017460508, -0.3925868, -0.41567528, 0.0791488},
		{-0.4372603, -0.6969509, -0.3109225, 0.41482833, 0.09164257, 0.12076251, 0.36866716, -0.08887269},
		{-0.031771045, 0.480221, 0.427551, -0.32297173, -0.16624491, 0.18685731, 0.1498896, 0.008926822},
		{0.40973613, 0.42175347, 0.4777475, 0.040032405, 0.032617908, 0.42604688, 0.11307899, 0.14878604},
		{-0.5137163, -0.4395494, -0.19909692, 0.11350988, 0.30058524, -0.12350479, -0.30272987, 0.37838307}
};

static const float bias_1[10] = {-0.072200745, -0.1296072, -0.098404236, -0.010049104, -0.061082475, -0.011206505, 0.08421902, 0.20837572, 0.03372369, 0.003031925};

static const float weights_1[10][13] = {
		{0.03421453, -0.1123306, -0.567483, -0.68150747, -0.16737612, -0.36208394, -0.6029331, -0.26671395, -0.281881, 0.037626397, -0.14112517, -0.48173794, -0.24816647},
		{-0.050071426, 0.3485594, -0.5952869, -0.08056127, 0.051638484, -0.41373163, 0.22272141, -0.31114274, 0.50808066, -0.09604176, -0.3257739, -0.055852965, 0.41566864},
		{0.5698976, -0.28288147, -0.084373534, 0.13686545, -0.4208315, -0.18387741, 0.31020662, 0.124808766, 0.49717864, 0.54932016, -0.1885672, -0.5481058, 0.10467455},
		{-0.40074176, 0.051410567, 0.47364593, -0.010722651, -0.3349539, 0.17955007, -0.38947183, 0.18318757, 0.04080097, -0.45282802, 0.33732906, 0.3095632, -0.09987623},
		{0.34514055, 0.26393807, 0.41766056, 0.4772061, 0.4146054, -0.26516986, 0.44127473, 0.13576017, 0.4337039, 0.012068406, 0.0039399634, -0.20495465, 0.712444},
		{0.55270326, 0.40200815, -0.004578526, 0.5345007, -0.42252085, 0.32227582, 0.4027434, -0.059154388, 0.18037128, 0.22374873, 0.0018779864, 0.2861029, 0.1666601},
		{0.34572524, -0.26744568, 0.2843208, -0.12600744, 0.08456165, 0.19508971, 0.2628316, 0.32605833, -0.031061921, 0.20931005, 0.56337875, -0.33353096, 0.28018883},
		{0.4321865, -0.56529725, 0.6189787, 0.5923617, 0.71329373, 0.5190063, 0.1387063, -0.473738, -0.3910035, 0.07370771, -0.05644161, 0.20187728, -0.75632375},
		{-0.24026018, -0.08719549, 0.3647169, -0.13035105, 0.011154194, -0.27148265, 0.1024573, -0.29618245, 0.1165276, -0.571709, 0.44156453, -0.056200486, 0.13587397},
		{0.1747133, 0.39812377, 0.38854966, 0.12042352, 0.37037748, 0.3253959, 0.45666236, -0.41826445, 0.32297385, 0.6004387, -0.24772473, -0.07240003, 0.5478078}
};

static const float bias_2[10] = {0.035804622, 0.080731764, 0.051206782, 0.09027686, 0.00094408786, 0.009680981, 0.07304122, 0.18457694, 0.07083316, 0.05439253};

static const float weights_2[10][10] = {
		{0.35211933, 0.22471572, 0.057780087, -0.09403473, -0.5224832, 0.14678292, -0.40497786, 0.22821675, 0.54488546, -0.08116238},
		{-0.014491109, -0.5698423, -0.31290144, -0.43105468, -0.070134655, 0.27070287, 0.023132514, 0.50759923, -0.16216914, 0.62147915},
		{-0.6936351, 0.3735469, 0.37985316, -0.13144079, 0.021442048, -0.29523522, -0.22361185, 0.64178216, 0.5434944, -0.13910614},
		{-0.09877744, -0.42882696, -0.5967387, 0.6460678, -0.62070364, -0.46089652, 0.3088074, 0.52734363, 0.2279579, -0.33697116},
		{0.06648687, 0.21696806, -0.10237934, 0.34099507, 0.054895688, 0.264485, 0.04185885, -0.34718204, 0.06394621, -0.33611092},
		{-0.060950913, -0.012644999, 0.41931358, 0.36339992, -0.1721479, 0.5071491, -0.1815326, 0.23578858, -0.4332013, 0.56487334},
		{-0.6082413, 0.28910592, 0.23009871, -0.41389108, 0.38517085, 0.18928938, 0.1826176, 0.18151294, 0.16085756, 0.38904414},
		{-0.46154413, 0.39561105, -0.61023974, -0.32039994, -0.4158184, -0.31770816, -0.13619196, 0.20559962, -0.2710954, -0.16264379},
		{-0.3186336, -0.36379147, -0.38761267, 0.06446749, 0.07857486, 0.0744851, 0.263865, -0.04538002, 0.16294037, 0.35855776},
		{-0.16899578, 0.17411526, -0.28790265, 0.11675391, -0.07490829, -0.46206823, 0.2627587, 0.6312582, -0.036645684, 0.41946855}
};

static const float bias_3[12] = {0.06463779, 0.0087525975, -0.01744647, -0.02378733, 0.042556386, 0.011172265, 0.004657856, -0.012377596, -0.009948247, -0.009998115, -0.007413654, -0.0034074504};

static const float weights_3[12][10] = {
		{0.3236038, 0.5822539, 0.118282415, -0.45465386, -0.4655946, 0.25855738, -0.11814765, 0.5371265, 0.18177113, 0.13944875},
		{-0.17932379, -0.44649026, -0.092168845, 0.39840516, -0.45124114, 0.4442237, 0.16355515, -0.09437618, 0.117552504, 0.42414185},
		{0.020116698, 0.11782154, 0.26669994, 0.04688394, 0.32487562, -0.38432127, -0.3092899, -0.31241846, -0.45614117, 0.1847863},
		{-0.06937762, -0.28406307, 0.4256447, -0.40971008, 0.26103273, 0.3324504, -0.087635644, -0.052699927, -0.0041321428, -0.5118591},
		{-0.15751825, 0.37249455, 0.006926105, -0.07720676, 0.34545887, 0.5302912, -0.07420197, 0.26136878, -0.36593202, -0.37796873},
		{-0.10007259, 0.053882144, 0.55288374, -0.28478873, -0.14439103, -0.23524396, 0.40207946, 0.21854357, 0.17613183, 0.49288195},
		{0.15918674, -0.007957154, 0.39322567, -0.13622132, -0.13486685, -0.40362698, -0.040365357, 0.095773466, -0.3747313, -0.45221046},
		{0.15605652, 0.45571998, -0.36458, 0.05979142, -0.17588152, 0.21566075, 0.56452024, -0.12531239, -0.12738575, -0.35011086},
		{-0.2439932, 0.2354043, -0.023242109, 0.28932178, -0.20866862, -0.042326737, 0.57735217, -0.29224488, -0.11612017, 0.13556409},
		{0.43422535, -0.50075895, 0.262802, 0.39732316, -0.22631913, -0.1931514, 0.2005103, -0.12137358, -0.04939119, -0.1682648},
		{0.19738512, -0.5801202, -0.06321492, 0.44579017, 0.50130975, 0.1124034, -0.10726236, -0.17886052, -0.2771254, 0.36050668},
		{-0.24276723, 0.049123466, 0.4565611, -0.0118161645, -0.13069743, 0.21253239, -0.37814513, -0.08539613, -0.19485463, 0.11235566}
};

static const float bias_4[1] = {0.010790792};

static const float weights_4[1][12] = {
		{0.5875026, 0.026937624, -0.15678178, 0.53539765, 0.26158604, -0.51169807, 0.19126716, -0.2627921, -0.61363626, 0.53431445, 0.611381, -0.38605466}
};

void ESP_NN_OPTIMIZED(const float input[INPUT_SIZE], float output[OUTPUT_SIZE])
{
	float output_0[13];

	for(int i = 0; i < 13; i++)
	{
		float res = 0;
		for(int j = 0; j < 8; j++)
		{
			res += input[j] * weights_0[i][j];
		}
		output_0[i] = elu(res + bias_0[i]);
	}

	float output_1[10];

	for(int i = 0; i < 10; i++)
	{
		float res = 0;
		for(int j = 0; j < 13; j++)
		{
			res += output_0[j] * weights_1[i][j];
		}
		output_1[i] = selu(res + bias_1[i]);
	}

	float output_2[10];

	for(int i = 0; i < 10; i++)
	{
		float res = 0;
		for(int j = 0; j < 10; j++)
		{
			res += output_1[j] * weights_2[i][j];
		}
		output_2[i] = exponential(res + bias_2[i]);
	}

	float output_3[12];

	for(int i = 0; i < 12; i++)
	{
		float res = 0;
		for(int j = 0; j < 10; j++)
		{
			res += output_2[j] * weights_3[i][j];
		}
		output_3[i] = softplus(res + bias_3[i]);
	}

	float output_4[1];

	for(int i = 0; i < 1; i++)
	{
		float res = 0;
		for(int j = 0; j < 12; j++)
		{
			res += output_3[j] * weights_4[i][j];
		}
		output_4[i] = sigmoid(res + bias_4[i]);
	}
	output[0] = output_4[0];
}